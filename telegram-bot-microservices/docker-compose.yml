services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: vitte_postgres
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-vitte_bot}
      POSTGRES_USER: ${POSTGRES_USER:-vitte_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_INITDB_ARGS: "--encoding=UTF-8 --lc-collate=C --lc-ctype=C"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    # NO EXTERNAL PORTS - internal network only
    expose:
      - "5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-vitte_user}"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1.5G
        reservations:
          cpus: '0.5'
          memory: 1G

  # Redis Cache & Broker
  redis:
    image: redis:7-alpine
    container_name: vitte_redis
    command: >
      redis-server
      --appendonly yes
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 1gb
      --maxmemory-policy allkeys-lru
    volumes:
      - redis_data:/data
    # NO EXTERNAL PORTS - internal network only
    expose:
      - "6379"
    healthcheck:
      test: ["CMD", "redis-cli", "--raw", "incr", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1.3G
        reservations:
          cpus: '0.25'
          memory: 1G

  # Qdrant Vector Database (Long-term Memory)
  qdrant:
    image: qdrant/qdrant:latest
    container_name: vitte_qdrant
    volumes:
      - qdrant_data:/qdrant/storage
    # NO EXTERNAL PORTS - internal network only
    expose:
      - "6333"
      - "6334"
    environment:
      - QDRANT__SERVICE__GRPC_PORT=6334
    healthcheck:
      test: ["CMD", "bash", "-c", "exec 3<>/dev/tcp/127.0.0.1/6333 && echo -e 'GET /readyz HTTP/1.1\\r\\nHost: localhost\\r\\nConnection: close\\r\\n\\r\\n' >&3 && grep -q 'HTTP/1.1 200' <&3"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M

  # Database Migrations (run once)
  migrations:
    build:
      context: .
      dockerfile: Dockerfile.migrations
    container_name: vitte_migrations
    env_file:
      - .env
    environment:
      - DATABASE_URL=${DATABASE_URL}
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - vitte_network
    restart: "no"

  # Telegram Bot Service
  bot:
    build:
      context: .
      dockerfile: services/bot/Dockerfile
    container_name: vitte_bot
    env_file:
      - .env
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - BOT_TOKEN=${BOT_TOKEN}
      - DATABASE_URL=${DATABASE_URL}
      - WEBAPP_URL=${WEBAPP_URL}
    depends_on:
      postgres:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # LLM Gateway Service
  llm-gateway:
    build:
      context: ./services/llm-gateway
      dockerfile: Dockerfile
    container_name: vitte_llm_gateway
    env_file:
      - .env
    environment:
      - PROXYAPI_API_KEY=${PROXYAPI_API_KEY}
      - OPENROUTER_BASE_URL=${OPENROUTER_BASE_URL}
      - VITTE_LLM_MODEL=${VITTE_LLM_MODEL}
      - REDIS_URL=${REDIS_URL_LLM}
    expose:
      - "8001"
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/v1/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # FastAPI Service
  api:
    build:
      context: .
      dockerfile: services/bot/api/Dockerfile
    container_name: vitte_api
    env_file:
      - .env
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - API_HOST=${API_HOST:-0.0.0.0}
      - API_PORT=${API_PORT:-8000}
      - DATABASE_URL=${DATABASE_URL}
      - LLM_GATEWAY_URL=http://llm-gateway:8001
      - OPENROUTER_API_KEY=${OPENROUTER_API_KEY}
      - QDRANT_URL=http://qdrant:6333
      - BOT_TOKEN=${BOT_TOKEN}
    # Internal only - access via Nginx
    expose:
      - "8000"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      llm-gateway:
        condition: service_started
      qdrant:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 700M

  # Web App (React Frontend)
  webapp:
    build:
      context: ./services/webapp
      dockerfile: Dockerfile
      args:
        - VITE_BACKEND_URL=${WEBAPP_BACKEND_URL:-}
        - VITE_DEBUG_MINIAPP=${VITE_DEBUG_MINIAPP:-0}
    container_name: vitte_webapp
    # Internal only - access via Nginx
    expose:
      - "3000"
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 30s
      timeout: 5s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

  # Celery Worker
  worker:
    build:
      context: .
      dockerfile: services/bot/worker/Dockerfile
    container_name: vitte_worker
    env_file:
      - .env
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DATABASE_URL=${DATABASE_URL}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1.2G
        reservations:
          cpus: '0.5'
          memory: 800M

  # Celery Beat (Scheduler)
  beat:
    build:
      context: .
      dockerfile: services/bot/worker/Dockerfile
    container_name: vitte_beat
    command: celery -A app.celery_app beat --scheduler redbeat.RedBeatScheduler --loglevel=info
    env_file:
      - .env
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - DATABASE_URL=${DATABASE_URL}
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.celery_app inspect ping -d celery@$$HOSTNAME 2>/dev/null || test -f /proc/1/status"]
      interval: 60s
      timeout: 15s
      start_period: 60s
      retries: 3
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # Image Generator Service (ComfyUI Integration)
  image-generator:
    build:
      context: .
      dockerfile: services/image-generator/Dockerfile
    container_name: vitte_image_generator
    env_file:
      - .env
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - COMFYUI_HOSTS=${COMFYUI_HOSTS:-195.209.210.175:8188,195.209.210.175:8189}
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_BROKER_DB=1
      - REDIS_RESULT_DB=2
      - REDIS_PASSWORD=${REDIS_PASSWORD}
      - BOT_TOKEN=${BOT_TOKEN}
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - MAX_CONCURRENT_GENERATIONS=${MAX_CONCURRENT_GENERATIONS:-2}
      - IMAGE_GENERATION_FREQUENCY=${IMAGE_GENERATION_FREQUENCY:-4}
      - GENERATION_TIMEOUT=${GENERATION_TIMEOUT:-120}
      - S3_ENDPOINT=minio:9000
      - S3_ACCESS_KEY=${MINIO_ROOT_USER:-minioadmin}
      - S3_SECRET_KEY=${MINIO_ROOT_PASSWORD}
      - S3_BUCKET_NAME=vitte-bot
      - S3_SECURE=false
      - PUBLIC_STORAGE_URL=https://craveme.tech/storage
    depends_on:
      redis:
        condition: service_healthy
      minio:
        condition: service_started
    healthcheck:
      test: ["CMD-SHELL", "celery -A app.tasks inspect ping -d image-generator@$$HOSTNAME 2>/dev/null || test -f /proc/1/status"]
      interval: 60s
      timeout: 15s
      start_period: 30s
      retries: 3
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Admin Panel
  admin:
    build:
      context: .
      dockerfile: services/bot/admin/Dockerfile
    container_name: vitte_admin
    env_file:
      - .env
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-production}
      - ADMIN_HOST=${ADMIN_HOST:-0.0.0.0}
      - ADMIN_PORT=${ADMIN_PORT:-8080}
      - DATABASE_URL=${DATABASE_URL}
      - MINIO_ENDPOINT=minio:9000
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
      - MINIO_BUCKET=broadcasts
      - MINIO_PUBLIC_URL=https://craveme.tech
    # Internal only - access via Nginx
    expose:
      - "8080"
    depends_on:
      migrations:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio:
        condition: service_started
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 600M
        reservations:
          cpus: '0.25'
          memory: 400M

  # Admin Panel (Next.js)
  admin-panel:
    build:
      context: ./services/admin-panel
      dockerfile: Dockerfile
    container_name: vitte_admin_panel
    environment:
      - ADMIN_API_URL=http://admin:8080
      - ADMIN_USER=${GRAFANA_USER:-admin}
      - ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - COOKIE_SECRET=${COOKIE_SECRET:-vitte-admin-panel-secret}
    expose:
      - "3100"
    depends_on:
      admin:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3100/admin-panel/api/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 15s
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M

  # Nginx Reverse Proxy
  nginx:
    build:
      context: .
      dockerfile: infrastructure/nginx/Dockerfile
    container_name: vitte_nginx
    ports:
      # ONLY these ports are exposed externally
      - "80:80"
      - "443:443"
    volumes:
      - /etc/letsencrypt:/etc/letsencrypt:ro
      - ../copy-of-story-cards/cropped_736x414:/var/www/persona-dialogs:ro
    depends_on:
      - api
      - admin
      - admin-panel
      - webapp
      - grafana
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # Prometheus (Monitoring)
  prometheus:
    image: prom/prometheus:latest
    container_name: vitte_prometheus
    user: "65534:65534"  # nobody user
    volumes:
      - ./infrastructure/monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    # Internal only - access via Nginx if needed
    expose:
      - "9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:9090/-/healthy"]
      interval: 30s
      timeout: 5s
      retries: 3
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 700M
        reservations:
          cpus: '0.25'
          memory: 500M

  # Grafana (Dashboards)
  grafana:
    image: grafana/grafana:latest
    container_name: vitte_grafana
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER:-admin}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_USERS_ALLOW_SIGN_UP=false
      - GF_SERVER_ROOT_URL=http://195.209.210.96/grafana/
      - GF_SERVER_SERVE_FROM_SUB_PATH=true
      - GF_INSTALL_PLUGINS=yesoreyeram-infinity-datasource
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - grafana_data:/var/lib/grafana
      - ./infrastructure/monitoring/grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./infrastructure/monitoring/grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - ./infrastructure/monitoring/grafana/dashboards:/etc/grafana/dashboards:ro
    # Internal only - access via Nginx
    expose:
      - "3000"
    depends_on:
      - prometheus
      - postgres
      - admin
    healthcheck:
      test: ["CMD", "wget", "--spider", "-q", "http://localhost:3000/api/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 400M
        reservations:
          cpus: '0.25'
          memory: 256M

  # MinIO Object Storage (S3-compatible)
  minio:
    image: minio/minio:latest
    container_name: vitte_minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    volumes:
      - minio_data:/data
    # Internal only - API on 9000, Console on 9001
    expose:
      - "9000"
      - "9001"
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    restart: unless-stopped
    networks:
      - vitte_network
    security_opt:
      - no-new-privileges:true
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M

networks:
  vitte_network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  qdrant_data:
  prometheus_data:
  grafana_data:
  minio_data:
